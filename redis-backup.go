//go:build !windows
// +build !windows

package main

import (
	"archive/tar"
	"bufio"
	"compress/gzip"
	"flag"
	"fmt"
	"io"
	"io/fs"
	"log"
	"os"
	"os/exec"
	"os/signal"
	"path/filepath"
	"sort"
	"strconv"
	"strings"
	"syscall"
	"time"

	"github.com/jlaffaye/ftp"
	"github.com/shirou/gopsutil/v3/net"
	"github.com/shirou/gopsutil/v3/process"
)

// Runtime-overrideable defaults
var (
	backupPath     string // root directory for all backups
	keepDays       int    // daily retention in days (local)
	maxCopies      int    // leave only <n> newest daily *.tar.gz (0 = unlimited)
	saveTimeoutSec int    // how long to wait for BGSAVE to finish

	// FTP related
	ftpConfFile          string
	ftpHost              string
	ftpUser              string
	ftpPass              string
	ftpKeepFactor        int // remote retention multiplier
	ftpEnabled           bool
	ftpKeepFactorFlagged bool

	// other runtime flags
	excludePortsCSV string
	checkHours      int
)

type ftpAccount struct {
	Host string
	User string
	Pass string
}

var ftpAccounts []ftpAccount

// internal helpers derived from flags
var excludePorts map[string]struct{}

// ANSI colors for terminal logs
const (
	green  = "\033[32m"
	yellow = "\033[33m"
	red    = "\033[31m"
	cyan   = "\033[36m"
	reset  = "\033[0m"
)

const lockFile = "/tmp/redis_backup.lock"
const backupSubdir = "redis-backup"

func main() {
	// Define flags
	listFlag := flag.Bool("list", false, "List backups and exit")
	restoreFlag := flag.Bool("restore", false, "Interactive restore wizard")
	helpFlag := flag.Bool("help", false, "Show help and exit")

	flag.StringVar(&backupPath, "backup-path", "/backup", "Root directory for backups")
	flag.IntVar(&keepDays, "days", 30, "Days to keep daily backups (local)")
	flag.IntVar(&maxCopies, "copies", 0, "Max number of daily snapshots to keep (0 = unlimited)")
	flag.IntVar(&saveTimeoutSec, "save-timeout", 600, "Seconds to wait until Redis finishes BGSAVE (default: 600)")

	flag.IntVar(&maxCopies, "c", 0, "Alias for --copies")

	// New: exclusion list and check
	flag.StringVar(&excludePortsCSV, "exclude-ports", "", "Comma-separated list of Redis ports to skip during backup/check")
	flag.IntVar(&checkHours, "check", 0, "Run integrity check; value = max allowed hours since last backup. 0 disables check mode.")

	// New: FTP options
	flag.StringVar(&ftpConfFile, "ftp-conf", "/etc/ftp-backup.conf", "Path to FTP credentials file")
	flag.StringVar(&ftpHost, "ftp-host", "", "Override FTP host (otherwise taken from conf file)")
	flag.StringVar(&ftpUser, "ftp-user", "", "Override FTP username (otherwise taken from conf file)")
	flag.StringVar(&ftpPass, "ftp-pass", "", "Override FTP password (otherwise taken from conf file)")
	flag.IntVar(&ftpKeepFactor, "ftp-keep-factor", 4, "Retention multiplier for FTP (remoteKeepDays = keepDays * factor)")

	flag.Parse()

	// –û—Ç–º–µ—á–∞–µ–º, –∑–∞–¥–∞–≤–∞–ª –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å --ftp-keep-factor –≤—Ä—É—á–Ω—É—é
	flag.Visit(func(f *flag.Flag) {
		if f.Name == "ftp-keep-factor" {
			ftpKeepFactorFlagged = true
		}
	})

	// –ï—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ —Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É –∫–æ–ø–∏—é –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
	// –ù–ï —Ç—Ä–æ–≥–∞–ª --ftp-keep-factor, —Ç–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ–∫–Ω–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞ FTP √ó4
	if !ftpKeepFactorFlagged && maxCopies == 1 {
		// 4 √ó –±–æ–ª—å—à–µ, —á–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
		ftpKeepFactor = 4
	}

	// Prepare exclusion map
	excludePorts = make(map[string]struct{})
	if excludePortsCSV != "" {
		for _, p := range strings.Split(excludePortsCSV, ",") {
			excludePorts[strings.TrimSpace(p)] = struct{}{}
		}
	}

	// Check if we are running in check mode first
	if checkHours > 0 {
		runCheckMode()
		return
	}

	// Normal operational modes
	switch {
	case *helpFlag:
		printHelp()
	case *listFlag:
		listBackups()
	case *restoreFlag:
		interactiveRestore()
	case checkHours > 0:
		runCheckMode()

	default:
		// ‚Üê –∑–¥–µ—Å—å ¬´–±–æ–µ–≤–æ–π¬ª —Ä–µ–∂–∏–º
		acquireLock()
		// –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–Ω—è—Ç–∏–µ –ª–æ–∫–∞ –¥–∞–∂–µ –ø—Ä–∏ ^C / kill
		defer releaseLock()
		sig := make(chan os.Signal, 1)
		signal.Notify(sig, syscall.SIGINT, syscall.SIGTERM)
		go func() { <-sig; releaseLock(); os.Exit(1) }()

		initFTP()
		runBackup()
	}

}

/******************** HELP ********************/
func printHelp() {
	exe := filepath.Base(os.Args[0])

	fmt.Printf("%süöÄ Smart & Friendly Redis Backup Tool%s\n", cyan, reset)
	fmt.Printf("%sBuilt by CHICHA ‚Äî good dog, great backups. üêïüíæ%s\n\n", cyan, reset)
	fmt.Printf("%sUSAGE%s\n  %s [flags]\n\n", cyan, reset, exe)

	fmt.Printf("%sGENERAL FLAGS%s\n", cyan, reset)
	fmt.Println("  --list                    List existing backups and exit")
	fmt.Println("  --restore                 Start interactive restore wizard")
	fmt.Println("  --backup-path <dir>       Root directory for backups (default: /backup)")
	fmt.Println("  --days <n>                Days to keep local daily backups (default: 30)")
	fmt.Println("  --copies, -c <n>          Keep only <n> newest daily backups (0 = unlimited)")
	fmt.Println("  --save-timeout <sec>      Max seconds to wait for BGSAVE (default: 600)")

	fmt.Printf("%sBACKUP CONTROL and MONITORING%s\n", cyan, reset)
	fmt.Println("  --exclude-ports <csv>     Comma‚Äëseparated list of Redis ports NOT to back up")
	fmt.Println("  --check <hours>           Verify freshness/size; CRITICAL if older than <hours>")

	fmt.Printf("%sFTP OFF‚ÄëSITE%s\n", cyan, reset)
	fmt.Println("  --ftp-conf <file>         Credentials file (default: /etc/ftp-backup.conf)")
	fmt.Println("  --ftp-host <host>         FTP host (overrides conf)")
	fmt.Println("  --ftp-user <user>         FTP username")
	fmt.Println("  --ftp-pass <pass>         FTP password")
	fmt.Println("  --ftp-keep-factor <n>     Store data on FTP n√ó longer than locally (default: 4)")

	fmt.Printf("%sEXAMPLES%s\n", cyan, reset)
	fmt.Printf("  # Basic backup\n  sudo %s\n\n", exe)
	fmt.Printf("  # Exclude session caches (ports 6380,6381)\n  sudo %s --exclude-ports 6380,6381\n\n", exe)
	fmt.Printf("  # Nagios check ‚Äì CRITICAL if older than 25‚ÄØh\n  %s --check 25\n", exe)

	// Live preview of detected Redis instances and RDB sizes
	fmt.Printf("\n%sDETECTED REDIS TARGETS%s\n", cyan, reset)
	ports := detectRedisPorts()
	if len(ports) == 0 {
		fmt.Println("  (no running redis-server instances found)")
		return
	}
	for _, port := range ports {
		dir := getRedisDir(port)
		file := getRedisRDB(port)
		if dir == "" || file == "" {
			continue
		}
		rdbPath := filepath.Join(dir, file)
		if info, err := os.Stat(rdbPath); err == nil {
			size := float64(info.Size()) / (1024 * 1024)
			fmt.Printf("  ‚Ä¢ port %s ‚Üí %s  (%.1f¬†MB)\n", port, rdbPath, size)
		}
	}
}

/**************** PERMISSION HELPERS *****************/
func suggestSudo(err error) {
	if err == nil {
		return
	}
	if os.IsPermission(err) || strings.Contains(err.Error(), "permission denied") {
		log.Printf("%sPermission denied ‚Äì you may need to run with sudo%s", yellow, reset)
	}
}

/******************** LIST ********************/
func listBackups() {
	host, _ := os.Hostname()
	root := filepath.Join(backupPath, host, backupSubdir) // ‚Üê –¥–æ–±–∞–≤–∏–ª–∏ backupSubdir

	entries, err := os.ReadDir(root)
	if err != nil {
		suggestSudo(err)
		log.Fatalf("%sCannot open %s: %v%s", red, root, err, reset)
	}

	for _, e := range entries {
		if e.IsDir() && strings.HasPrefix(e.Name(), "redis_") {
			daily := filepath.Join(root, e.Name(), "daily")
			fmt.Printf("%süìÇ %s%s\n", cyan, e.Name(), reset)
			files, _ := os.ReadDir(daily)
			for _, f := range files {
				fmt.Printf("  ‚Ä¢ %s\n", f.Name())
			}
		}
	}
}

/**************** INTERACTIVE RESTORE *********/
func interactiveRestore() {
	host, _ := os.Hostname()
	root := filepath.Join(backupPath, host, backupSubdir) // ‚Üê –¥–æ–±–∞–≤–∏–ª–∏ backupSubdir
	reader := bufio.NewReader(os.Stdin)

	dirs, err := os.ReadDir(root)
	if err != nil {
		suggestSudo(err)
		fmt.Printf("%sCannot open %s: %v%s\n", red, root, err, reset)
		return
	}

	var ports []string
	for _, d := range dirs {
		if d.IsDir() && strings.HasPrefix(d.Name(), "redis_") {
			ports = append(ports, strings.TrimPrefix(d.Name(), "redis_"))
		}
	}
	if len(ports) == 0 {
		fmt.Printf("%sNo backups found.%s\n", red, reset)
		return
	}

	fmt.Println("Select Redis port to restore:")
	for i, p := range ports {
		fmt.Printf("  [%d] %s\n", i+1, p)
	}
	fmt.Print(">>> ")
	line, _ := reader.ReadString('\n')
	idx, _ := strconv.Atoi(strings.TrimSpace(line))
	if idx < 1 || idx > len(ports) {
		fmt.Println("Invalid choice")
		return
	}
	port := ports[idx-1]

	dailyDir := filepath.Join(root, "redis_"+port, "daily") // ‚Üê –ø—É—Ç—å —á–µ—Ä–µ–∑ backupSubdir
	files, err := os.ReadDir(dailyDir)
	if err != nil {
		suggestSudo(err)
		fmt.Printf("%sCannot read %s: %v%s\n", red, dailyDir, err, reset)
		return
	}
	if len(files) == 0 {
		fmt.Printf("%sNo archives for port %s%s\n", red, port, reset)
		return
	}

	fmt.Println("Select archive:")
	for i, f := range files {
		fmt.Printf("  [%d] %s\n", i+1, f.Name())
	}
	fmt.Print(">>> ")
	line, _ = reader.ReadString('\n')
	idx, _ = strconv.Atoi(strings.TrimSpace(line))
	if idx < 1 || idx > len(files) {
		fmt.Println("Invalid choice")
		return
	}
	archive := files[idx-1].Name()

	fmt.Printf("%s‚ö†  Redis %s will be restored from %s. Continue? (y/N): %s",
		yellow, port, archive, reset)
	confirm, _ := reader.ReadString('\n')
	confirm = strings.ToLower(strings.TrimSpace(confirm))
	if confirm != "y" && confirm != "yes" {
		fmt.Println("Cancelled.")
		return
	}

	restoreBackup(port, archive) // restoreBackup —Ç–æ–∂–µ –æ–±–Ω–æ–≤–ª—ë–Ω, —Å–º. –Ω–∏–∂–µ
}

/******************* BACKUP LOOP *******************/
func runBackup() {
	now := time.Now()
	host, _ := os.Hostname()

	ports := detectRedisPorts()
	if len(ports) == 0 {
		log.Println("‚ùå No redis-server processes found.")
		return
	}

	for _, port := range ports {
		if _, skip := excludePorts[port]; skip {
			log.Printf("%sSkipping Redis %s (excluded)%s", yellow, port, reset)
			continue
		}

		if !isRedisHealthy(port) {
			log.Printf("%sRedis %s is not readable ‚Äì skipping backup%s", yellow, port, reset)
			continue
		}

		dir := getRedisDir(port)
		file := getRedisRDB(port)
		if dir == "" || file == "" {
			log.Printf("‚ö†  Redis %s: cannot determine dir or RDB file\n", port)
			continue
		}
		rdbPath := filepath.Join(dir, file)
		if _, err := os.Stat(rdbPath); err != nil {
			suggestSudo(err)
			log.Printf("%sFile not found or inaccessible: %s%s", red, rdbPath, reset)
			continue
		}
		log.Printf("%s‚úî Redis %s ‚Üí %s%s", green, port, rdbPath, reset)
		archivePath := backupInstance(port, rdbPath, host, now)

		// FTP replication
		if ftpEnabled && archivePath != "" {
			remoteRel := strings.TrimPrefix(archivePath, backupPath)
			remoteRel = strings.TrimPrefix(remoteRel, string(os.PathSeparator))
			uploadToFTP(archivePath, remoteRel)
		}
		log.Printf("%s----------------------------------------%s", cyan, reset)
	}
}

/***************** REDIS HELPERS *******************/

func detectRedisPorts() []string {
	seen := make(map[string]struct{}) // <- –Ω–æ–≤–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ
	var ports []string

	conns, err := net.Connections("tcp") // tcp4+tcp6 = –¥—É–±–ª–∏–∫–∞—Ç—ã
	if err != nil {
		log.Println("net.Connections error:", err)
		return nil
	}

	for _, c := range conns {
		if c.Status != "LISTEN" || c.Pid == 0 || c.Laddr.Port == 0 {
			continue
		}

		proc, _ := process.NewProcess(c.Pid)
		name, _ := proc.Name()
		if !strings.Contains(strings.ToLower(name), "redis-server") {
			continue
		}

		p := strconv.Itoa(int(c.Laddr.Port))
		seen[p] = struct{}{} // –∫–ª–∞–¥—ë–º –≤ set
	}

	for p := range seen { // –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ä–µ–∑
		ports = append(ports, p)
	}
	sort.Strings(ports) // (—á—Ç–æ–±—ã –ø–æ—Ä—è–¥–æ–∫ –±—ã–ª —Å—Ç–∞–±–∏–ª—å–Ω—ã–º)
	return ports
}

func getRedisDir(port string) string {
	out, err := exec.Command("redis-cli", "-p", port, "CONFIG", "GET", "dir").Output()
	if err != nil {
		suggestSudo(err)
		return ""
	}
	parts := strings.Split(strings.TrimSpace(string(out)), "\n")
	if len(parts) >= 2 {
		return strings.TrimSpace(parts[1])
	}
	return ""
}

func getRedisRDB(port string) string {
	out, err := exec.Command("redis-cli", "-p", port, "CONFIG", "GET", "dbfilename").Output()
	if err != nil {
		suggestSudo(err)
		return ""
	}
	parts := strings.Split(strings.TrimSpace(string(out)), "\n")
	if len(parts) >= 2 {
		return strings.TrimSpace(parts[1])
	}
	return ""
}

/**************** BACKUP SINGLE INSTANCE ************/
func backupInstance(port, rdbPath, host string, now time.Time) string {
	inst := "redis_" + port
	base := filepath.Join(backupPath, host, backupSubdir, inst) // ‚Üê –¥–æ–±–∞–≤–∏–ª–∏ backupSubdir

	daily := filepath.Join(base, "daily")
	weekly := filepath.Join(base, "weekly")
	monthly := filepath.Join(base, "monthly")
	yearly := filepath.Join(base, "yearly")

	for _, d := range []string{daily, weekly, monthly, yearly} {
		if err := os.MkdirAll(d, 0755); err != nil {
			suggestSudo(err)
			log.Printf("mkdir %s: %v", d, err)
			return ""
		}
	}

	ts := now.Format("2006-01-02_15-04-05")
	archive := filepath.Join(daily, fmt.Sprintf("%s_%s.tar.gz", ts, inst))

	log.Printf("%süì¶ Archiving %s ‚Ä¶%s", cyan, archive, reset)
	if err := createTarGz(archive, []string{rdbPath}); err != nil {
		suggestSudo(err)
		log.Printf("%sArchive error: %v%s", red, err, reset)
		return ""
	}
	printFileSize(archive)

	if now.Weekday() == time.Sunday {
		copyFile(archive, filepath.Join(weekly, filepath.Base(archive)))
	}
	if now.Day() == 1 {
		copyFile(archive, filepath.Join(monthly, filepath.Base(archive)))
	}
	if now.YearDay() == 1 {
		copyFile(archive, filepath.Join(yearly, filepath.Base(archive)))
	}

	if maxCopies > 0 {
		rotateCopies(daily, maxCopies)
	} else {
		cleanupOldFiles(daily, keepDays)
	}

	return archive
}

/********************** RESTORE ************************/
func restoreBackup(port, archiveName string) {
	host, _ := os.Hostname()
	inst := "redis_" + port
	archivePath := filepath.Join(backupPath, host, backupSubdir, // ‚Üê –¥–æ–±–∞–≤–∏–ª–∏ backupSubdir
		inst, "daily", archiveName)

	if _, err := os.Stat(archivePath); err != nil {
		suggestSudo(err)
		log.Fatalf("%sArchive %s not found%s", red, archivePath, reset)
	}

	restoreDir := getRedisDir(port)
	fileName := getRedisRDB(port)
	if restoreDir == "" || fileName == "" {
		log.Fatalf("%sCannot determine Redis directory for port %s%s", red, port, reset)
	}

	currentFile := filepath.Join(restoreDir, fileName)

	// --- —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π RDB (–µ—Å–ª–∏ –±—ã–ª) ---
	var origUID, origGID int
	var origMode os.FileMode

	if info, err := os.Stat(currentFile); err == nil {
		if stat, ok := info.Sys().(*syscall.Stat_t); ok {
			origUID = int(stat.Uid)
			origGID = int(stat.Gid)
		}
		origMode = info.Mode()
		backupName := currentFile + ".backup"
		log.Printf("%süîÅ Renaming current RDB ‚Üí %s%s", yellow, backupName, reset)
		if err := os.Rename(currentFile, backupName); err != nil {
			suggestSudo(err)
			log.Fatalf("%sCannot rename current file: %v%s", red, err, reset)
		}
	}

	log.Printf("%süîÑ Extracting %s ‚Üí %s%s", cyan, archiveName, restoreDir, reset)
	if err := extractTarGz(archivePath, restoreDir); err != nil {
		suggestSudo(err)
		log.Fatalf("%sRestore error: %v%s", red, err, reset)
	}

	newFile := filepath.Join(restoreDir, fileName)
	if origMode != 0 {
		_ = os.Chmod(newFile, origMode)
	}
	if origUID != 0 || origGID != 0 {
		_ = os.Chown(newFile, origUID, origGID)
	}

	log.Printf("%s‚úî Restore complete%s", green, reset)
}

/********************** FTP ***************************/
func initFTP() {
	// 1) —á–∏—Ç–∞–µ–º –∫–æ–Ω—Ñ–∏–≥-—Ñ–∞–π–ª, –µ—Å–ª–∏ –µ—Å—Ç—å
	if _, err := os.Stat(ftpConfFile); err == nil {
		_ = parseFTPConf(ftpConfFile)
	}

	// 2) –µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã —Ñ–ª–∞–≥–∏ host/user/pass ‚Äì —Å—á–∏—Ç–∞–µ–º –∏—Ö –≤—ã—Å—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
	if ftpHost != "" {
		ftpAccounts = []ftpAccount{{Host: ftpHost, User: ftpUser, Pass: ftpPass}}
	}

	ftpEnabled = len(ftpAccounts) > 0
	if !ftpEnabled {
		return
	}

	// 3) –≤—ã–≤–æ–¥–∏–º –≤—Å–µ —Ç–∞—Ä–≥–µ—Ç—ã
	for _, acc := range ftpAccounts {
		log.Printf("%süåê FTP replication target ‚Üí %s (user %s)%s",
			cyan, acc.Host, acc.User, reset)
	}
}

func parseFTPConf(path string) error {
	f, err := os.Open(path)
	if err != nil {
		return err
	}
	defer f.Close()

	var cur ftpAccount
	commit := func() {
		if cur.Host != "" && cur.User != "" && cur.Pass != "" {
			ftpAccounts = append(ftpAccounts, cur)
		}
		cur = ftpAccount{}
	}

	scanner := bufio.NewScanner(f)
	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		if line == "" || strings.HasPrefix(line, "#") || !strings.Contains(line, "=") {
			continue
		}
		kv := strings.SplitN(line, "=", 2)
		key := strings.Trim(kv[0], " \"")
		val := strings.Trim(kv[1], " \"")

		switch key {
		case "FTP_HOST":
			// –ø—Ä–∏ —Å–º–µ–Ω–µ —Ö–æ—Å—Ç–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –±–ª–æ–∫
			if cur.Host != "" {
				commit()
			}
			cur.Host = val
		case "FTP_USER":
			cur.User = val
		case "FTP_PASS":
			cur.Pass = val
		}
	}
	commit() // –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫
	return scanner.Err()
}

func uploadToSingleFTP(acc ftpAccount, localPath, remoteRel string) {
	c, err := ftp.Dial(acc.Host + ":21")
	if err != nil {
		log.Printf("%sFTP dial %s: %v%s", red, acc.Host, err, reset)
		return
	}
	defer c.Quit()

	if err := c.Login(acc.User, acc.Pass); err != nil {
		log.Printf("%sFTP login %s: %v%s", red, acc.Host, err, reset)
		return
	}

	// —Å–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
	parts := strings.Split(filepath.Dir(remoteRel), string(os.PathSeparator))
	cwd := "/"
	for _, p := range parts {
		if p == "" {
			continue
		}
		cwd = filepath.Join(cwd, p)
		_ = c.MakeDir(cwd)
	}

	f, err := os.Open(localPath)
	if err != nil {
		log.Printf("%sFTP open local: %v%s", red, err, reset)
		return
	}
	defer f.Close()

	remotePath := filepath.ToSlash(remoteRel)
	log.Printf("%s‚á™ Uploading to %s: %s%s", cyan, acc.Host, remotePath, reset)
	if err := c.Stor(remotePath, f); err != nil {
		log.Printf("%sFTP upload %s: %v%s", red, acc.Host, err, reset)
		return
	}

	// —Ä–æ—Ç–∞—Ü–∏—è
	if strings.Contains(remotePath, "/daily/") {
		remoteDailyDir := filepath.ToSlash(filepath.Dir(remotePath))
		if maxCopies > 0 {
			rotateCopiesFTP(c, remoteDailyDir, maxCopies*ftpKeepFactor)
		} else {
			cleanupOldFilesFTP(c, remoteDailyDir, keepDays*ftpKeepFactor)
		}
	}
}

func uploadToFTP(localPath, remoteRel string) {
	if !ftpEnabled {
		return
	}
	for _, acc := range ftpAccounts {
		uploadToSingleFTP(acc, localPath, remoteRel)
	}
}

func cleanupOldFilesFTP(c *ftp.ServerConn, dir string, days int) {
	entries, err := c.List(dir)
	if err != nil {
		return
	}
	cutoff := time.Now().AddDate(0, 0, -days)
	for _, e := range entries {
		if e.Type != ftp.EntryTypeFile {
			continue
		}
		if e.Time.Before(cutoff) {
			remoteFile := filepath.ToSlash(filepath.Join(dir, e.Name))
			log.Printf("üßπ (FTP) Deleting old archive %s", remoteFile)
			_ = c.Delete(remoteFile)
		}
	}
}

/********************** CHECK MODE ********************/
func runCheckMode() {
	// ‚Äî--- —Ä–∞–∑–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é FTP, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
	if _, err := os.Stat(ftpConfFile); err == nil {
		_ = parseFTPConf(ftpConfFile)
	}

	if len(ftpAccounts) > 0 {
		ftpEnabled = true
	}

	if ftpHost != "" { // –º–æ–≥–ª–∏ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–ª–∞–≥–∞–º–∏
		ftpEnabled = true
	}

	host, _ := os.Hostname()
	now := time.Now()
	threshold := now.Add(-time.Duration(checkHours) * time.Hour) // ¬´—Å–≤–µ–∂–µ—Å—Ç—å¬ª –±—ç–∫–∞–ø–∞

	problems := []string{}
	severity := 0 // 0-OK, 1-WARNING, 2-CRITICAL

	/************* –õ–û–ö–ê–õ–¨–ù–´–ï –ë–≠–ö–ê–ü–´ *************/
	totalSize, _ := dirSize(filepath.Join(backupPath, host, backupSubdir))

	var latestSetSize int64
	var latestFiles int

	ports := detectRedisPorts()
	for _, port := range ports {
		if _, skip := excludePorts[port]; skip {
			continue
		}

		inst := "redis_" + port
		dailyDir := filepath.Join(backupPath, host, backupSubdir, inst, "daily")
		latestFile, latestMTime := findLatestArchive(dailyDir)

		if latestFile == "" {
			problems = append(problems, fmt.Sprintf("Redis %s: NO BACKUP", port))
			severity = max(severity, 2)
			continue
		}
		if latestMTime.Before(threshold) {
			problems = append(problems,
				fmt.Sprintf("Redis %s: older than %d h", port, checkHours))
			severity = max(severity, 2)
		}

		if fi, err := os.Stat(latestFile); err == nil {
			latestSetSize += fi.Size()
			latestFiles++
		}

		// —É—Å—ã—Ö–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞
		currentRDB := filepath.Join(getRedisDir(port), getRedisRDB(port))
		if sizeOK, err := compareSizes(currentRDB, latestFile); err == nil && !sizeOK {
			problems = append(problems,
				fmt.Sprintf("Redis %s: backup size <75%%", port))
			severity = max(severity, 2)
		}
	}

	/************* –î–ò–°–ö *************/
	var copiesPossible int64
	var diskFree, diskTotal int64
	var usedPct float64
	if latestSetSize > 0 {
		var errDisk error
		diskTotal, diskFree, errDisk = diskUsage(backupPath)
		if errDisk != nil {
			problems = append(problems, fmt.Sprintf("disk stat: %v", errDisk))
		}

		copiesPossible = diskFree / latestSetSize
		usedPct = float64(totalSize) / float64(diskTotal) * 100

		if copiesPossible < 5 || usedPct >= 90 {
			severity = max(severity, 2)
			problems = append(problems, "disk pressure CRITICAL")
		} else if copiesPossible < 24 || usedPct >= 80 {
			severity = max(severity, 1)
			problems = append(problems, "disk pressure WARNING")
		}
	}

	/************* FTP-–ë–≠–ö–ê–ü–´ (–µ—Å–ª–∏ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω FTP) *************/
	var ftpLatestSetSize int64
	var ftpLatestFiles int
	if ftpEnabled {
		expectedFtpCopies := 0
		if maxCopies > 0 {
			expectedFtpCopies = maxCopies * ftpKeepFactor
		}

		for _, acc := range ftpAccounts {
			c, err := ftp.Dial(acc.Host+":21", ftp.DialWithTimeout(5*time.Second))
			if err != nil {
				problems = append(problems, fmt.Sprintf("FTP connect %s: %v", acc.Host, err))
				severity = max(severity, 2)
				continue
			}
			if err := c.Login(acc.User, acc.Pass); err != nil {
				problems = append(problems, fmt.Sprintf("FTP login %s: %v", acc.Host, err))
				severity = max(severity, 2)
				_ = c.Quit()
				continue
			}

			for _, port := range ports {
				if _, skip := excludePorts[port]; skip {
					continue
				}
				remoteDaily := filepath.ToSlash(filepath.Join("/",
					host, backupSubdir, "redis_"+port, "daily"))

				// —Å–≤–µ–∂–∏–π –∞—Ä—Ö–∏–≤
				latestPath, latestSize, latestTime := findLatestFTPArchive(c, remoteDaily)
				if latestPath == "" {
					problems = append(problems,
						fmt.Sprintf("FTP %s redis %s: NO BACKUP", acc.Host, port))
					severity = max(severity, 2)
					continue
				}
				if latestTime.Before(threshold) {
					problems = append(problems,
						fmt.Sprintf("FTP %s redis %s: older than %d h", acc.Host, port, checkHours))
					severity = max(severity, 2)
				}

				// –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ø–∏–π
				if expectedFtpCopies > 0 {
					entries, _ := c.List(remoteDaily)
					var cnt int
					for _, e := range entries {
						if e.Type == ftp.EntryTypeFile && strings.HasSuffix(e.Name, ".tar.gz") {
							cnt++
						}
					}
					if cnt < expectedFtpCopies {
						problems = append(problems,
							fmt.Sprintf("FTP %s redis %s: only %d/%d copies",
								acc.Host, port, cnt, expectedFtpCopies))
						severity = max(severity, 1) // warning
					}
				}

				ftpLatestSetSize += latestSize
				ftpLatestFiles++
			}
			_ = c.Quit()
		}
	}

	/************* –ö–†–ê–°–ò–í–´–ï –°–¢–†–û–ö–ò –ú–ï–¢–†–ò–ö *************/
	localMetrics := fmt.Sprintf(
		"Backups total: %.1f MB (%d files); full set: %.1f MB; free: %.1f MB; can store ‚âà %d full sets; used by backups: %.1f%%",
		humanMB(totalSize), latestFiles, humanMB(latestSetSize),
		humanMB(diskFree), copiesPossible, usedPct)

	ftpMetrics := ""
	if ftpEnabled && ftpLatestFiles > 0 {
		ftpMetrics = fmt.Sprintf("FTP latest full set: %.1f MB (%d files)",
			humanMB(ftpLatestSetSize), ftpLatestFiles)
	}

	/************* –í–´–í–û–î –î–õ–Ø NAGIOS: –°–¢–ê–¢–£–° ‚Üí –î–ï–¢–ê–õ–ò *************/
	var statusText string
	switch severity {
	case 2:
		statusText = "CRITICAL"
	case 1:
		statusText = "WARNING"
	default:
		statusText = "OK"
	}

	details := "all redis backups fresh and sufficiently sized. üëç"
	if len(problems) > 0 {
		details = strings.Join(problems, "; ")
	}

	fmt.Printf("%s: %s\n", statusText, details) // ‚Üê —Å–Ω–∞—á–∞–ª–∞ —Å—Ç–∞—Ç—É—Å
	fmt.Println(localMetrics)
	if ftpMetrics != "" {
		fmt.Println(ftpMetrics)
	}

	switch severity {
	case 2:
		os.Exit(2)
	case 1:
		os.Exit(1)
	default:
		os.Exit(0)
	}
}

/***************** FTP helper: —Å–≤–µ–∂–∏–π –∞—Ä—Ö–∏–≤ *****************/
func findLatestFTPArchive(c *ftp.ServerConn, dir string) (string, int64, time.Time) {
	entries, err := c.List(dir)
	if err != nil || len(entries) == 0 {
		return "", 0, time.Time{}
	}
	var newest string
	var newestTime time.Time
	var newestSize int64
	for _, e := range entries {
		if e.Type != ftp.EntryTypeFile || !strings.HasSuffix(e.Name, ".tar.gz") {
			continue
		}
		if e.Time.After(newestTime) {
			newestTime = e.Time
			newest = filepath.ToSlash(filepath.Join(dir, e.Name))
			newestSize = int64(e.Size)
		}
	}
	return newest, newestSize, newestTime
}

func max(a, b int) int {
	if b > a {
		return b
	}
	return a
}

func findLatestArchive(dir string) (string, time.Time) {
	files, err := os.ReadDir(dir)
	if err != nil || len(files) == 0 {
		return "", time.Time{}
	}
	var newest string
	var newestTime time.Time
	for _, f := range files {
		if f.IsDir() || !strings.HasSuffix(f.Name(), ".tar.gz") {
			continue
		}
		path := filepath.Join(dir, f.Name())
		if info, err := os.Stat(path); err == nil {
			if info.ModTime().After(newestTime) {
				newestTime = info.ModTime()
				newest = path
			}
		}
	}
	return newest, newestTime
}

func compareSizes(originalPath, archivePath string) (bool, error) {
	// size of original RDB
	origInfo, err := os.Stat(originalPath)
	if err != nil {
		return true, err // ignore if cannot stat original
	}
	origSize := origInfo.Size()

	// extract temp file to check size (stream) ‚Äì we only need the uncompressed payload of tar entry
	f, err := os.Open(archivePath)
	if err != nil {
		return true, err
	}
	defer f.Close()
	gr, err := gzip.NewReader(f)
	if err != nil {
		return true, err
	}
	defer gr.Close()
	tr := tar.NewReader(gr)
	hdr, err := tr.Next()
	if err != nil {
		return true, err
	}
	backupSize := hdr.Size

	return float64(backupSize) >= 0.75*float64(origSize), nil
}

/********************** FILE OPS **********************/
func createTarGz(dst string, files []string) error {
	out, err := os.Create(dst)
	if err != nil {
		suggestSudo(err)
		return err
	}
	defer out.Close()

	gw := gzip.NewWriter(out)
	defer gw.Close()

	tw := tar.NewWriter(gw)
	defer tw.Close()

	for _, file := range files {
		info, err := os.Stat(file)
		if err != nil {
			suggestSudo(err)
			return err
		}
		hdr, err := tar.FileInfoHeader(info, "")
		if err != nil {
			return err
		}
		hdr.Name = filepath.Base(file)
		if err := tw.WriteHeader(hdr); err != nil {
			return err
		}
		f, err := os.Open(file)
		if err != nil {
			suggestSudo(err)
			return err
		}
		if _, err := io.Copy(tw, f); err != nil {
			f.Close()
			return err
		}
		f.Close()
	}
	return nil
}

func extractTarGz(src, dest string) error {
	f, err := os.Open(src)
	if err != nil {
		suggestSudo(err)
		return err
	}
	defer f.Close()
	gr, err := gzip.NewReader(f)
	if err != nil {
		return err
	}
	defer gr.Close()
	tr := tar.NewReader(gr)
	for {
		hdr, err := tr.Next()
		if err == io.EOF {
			break
		}
		if err != nil {
			return err
		}
		outPath := filepath.Join(dest, hdr.Name)
		of, err := os.Create(outPath)
		if err != nil {
			suggestSudo(err)
			return err
		}
		if _, err := io.Copy(of, tr); err != nil {
			of.Close()
			return err
		}
		of.Close()
		_ = os.Chmod(outPath, os.FileMode(hdr.Mode))
		_ = os.Chown(outPath, hdr.Uid, hdr.Gid)
	}
	return nil
}

func copyFile(src, dst string) {
	in, err := os.Open(src)
	if err != nil {
		suggestSudo(err)
		log.Printf("open %s: %v", src, err)
		return
	}
	defer in.Close()
	out, err := os.Create(dst)
	if err != nil {
		suggestSudo(err)
		log.Printf("create %s: %v", dst, err)
		return
	}
	defer out.Close()
	_, _ = io.Copy(out, in)
	_ = os.Chmod(dst, 0644)
}

func printFileSize(path string) {
	if info, err := os.Stat(path); err == nil {
		size := float64(info.Size()) / (1024 * 1024)
		log.Printf("%süíæ Archive size: %.2f MB%s", green, size, reset)
	}
}

func cleanupOldFiles(dir string, days int) {
	files, _ := filepath.Glob(filepath.Join(dir, "*.tar.gz"))
	cutoff := time.Now().AddDate(0, 0, -days)
	for _, f := range files {
		if info, err := os.Stat(f); err == nil && info.ModTime().Before(cutoff) {
			log.Printf("üßπ Deleting old archive %s", filepath.Base(f))
			_ = os.Remove(f)
		}
	}
}

func acquireLock() {
	try := func() error {
		f, err := os.OpenFile(lockFile, os.O_CREATE|os.O_EXCL|os.O_WRONLY, 0644)
		if err != nil {
			return err // —É–∂–µ –µ—Å—Ç—å —Ñ–∞–π–ª
		}
		defer f.Close()
		_, _ = f.WriteString(strconv.Itoa(os.Getpid()))
		return nil // –ª–æ–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞
	}

	if err := try(); err == nil {
		return
	}

	// —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äì –ø—Ä–æ–≤–µ—Ä—è–µ–º –∂–∏–≤ –ª–∏ –≤–ª–∞–¥–µ–ª–µ—Ü
	data, _ := os.ReadFile(lockFile)
	if pid, _ := strconv.Atoi(strings.TrimSpace(string(data))); pid > 0 {
		if proc, _ := os.FindProcess(pid); proc != nil &&
			proc.Signal(syscall.Signal(0)) == nil {
			log.Fatalf("%sBackup already running (PID %d)%s", red, pid, reset)
		}
	}

	// –≤–ª–∞–¥–µ–ª–µ—Ü —É–º–µ—Ä ‚Äì —É–¥–∞–ª—è–µ–º ¬´–≤–∏—Å—è—â–∏–π¬ª –ª–æ–∫ –∏ –ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑
	_ = os.Remove(lockFile)
	if err := try(); err != nil {
		log.Fatalf("%sCannot create lock file: %v%s", red, err, reset)
	}
}

func releaseLock() {
	_ = os.Remove(lockFile)
}

func dirSize(root string) (int64, error) {
	var sum int64
	err := filepath.WalkDir(root, func(path string, d fs.DirEntry, err error) error {
		if err != nil || d.IsDir() || !strings.HasSuffix(d.Name(), ".tar.gz") {
			return err
		}
		if fi, err := os.Stat(path); err == nil {
			sum += fi.Size()
		}
		return nil
	})
	return sum, err
}

func humanMB(b int64) float64 { return float64(b) / (1024 * 1024) }

// isRedisHealthy triggers BGSAVE and waits until it finishes.
// Returns true if Redis answers PING and creates a fresh RDB
// within --save-timeout seconds.
func isRedisHealthy(port string) bool {
	// 1) –ø—Ä–æ—Å—Ç–æ–π PING
	out, err := exec.Command("redis-cli", "-p", port, "--raw", "PING").Output()
	if err != nil || strings.TrimSpace(string(out)) != "PONG" {
		return false
	}

	// 2) –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
	beforeStr, err := exec.Command("redis-cli", "-p", port, "--raw", "LASTSAVE").Output()
	if err != nil {
		return false
	}
	before, _ := strconv.ParseInt(strings.TrimSpace(string(beforeStr)), 10, 64)

	// 3) –∑–∞–ø—É—Å–∫–∞–µ–º BGSAVE (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º ¬´save in progress¬ª-–æ—à–∏–±–∫—É)
	_, _ = exec.Command("redis-cli", "-p", port, "BGSAVE").Output()

	// 4) –∂–¥—ë–º, –ø–æ–∫–∞ LASTSAVE —Å—Ç–∞–Ω–µ—Ç –Ω–æ–≤–µ–µ
	deadline := time.Now().Add(time.Duration(saveTimeoutSec) * time.Second)
	for time.Now().Before(deadline) {
		time.Sleep(2 * time.Second)
		if time.Now().Add(-30 * time.Second).After(deadline) {
			log.Printf("%s‚åõ Redis %s: still waiting for BGSAVE ‚Ä¶%s", yellow, port, reset)
		}

		afterStr, err := exec.Command("redis-cli", "-p", port, "--raw", "LASTSAVE").Output()
		if err != nil {
			return false
		}
		after, _ := strconv.ParseInt(strings.TrimSpace(string(afterStr)), 10, 64)

		if after > before {
			return true // –¥–∞–º–ø –≥–æ—Ç–æ–≤
		}
	}
	// —Ç–∞–π–º–∞—É—Ç: –¥–∞–º–ø –Ω–µ –ø–æ—è–≤–∏–ª—Å—è
	return false
}

// rotateCopies keeps only <copies> newest *.tar.gz in dir.
func rotateCopies(dir string, copies int) {
	files, _ := filepath.Glob(filepath.Join(dir, "*.tar.gz"))
	if len(files) <= copies {
		return
	}
	sort.Slice(files, func(i, j int) bool {
		fi, _ := os.Stat(files[i])
		fj, _ := os.Stat(files[j])
		return fi.ModTime().After(fj.ModTime())
	})
	for _, f := range files[copies:] {
		log.Printf("üßπ Deleting extra archive %s", filepath.Base(f))
		_ = os.Remove(f)
	}
}

// rotateCopiesFTP keeps only <copies> newest *.tar.gz in an FTP directory.
func rotateCopiesFTP(c *ftp.ServerConn, dir string, copies int) {
	entries, err := c.List(dir)
	if err != nil {
		return
	}

	// —Ä–∞–±–æ—Ç–∞–µ–º —Å —É–∫–∞–∑–∞—Ç–µ–ª—è–º–∏
	var files []*ftp.Entry
	for _, e := range entries {
		if e.Type == ftp.EntryTypeFile && strings.HasSuffix(e.Name, ".tar.gz") {
			files = append(files, e)
		}
	}
	if len(files) <= copies {
		return // –Ω–∏—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å
	}

	// —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏: –Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ
	sort.Slice(files, func(i, j int) bool {
		return files[i].Time.After(files[j].Time)
	})

	// —É–¥–∞–ª—è–µ–º ¬´–ª–∏—à–Ω–∏–µ¬ª —Ñ–∞–π–ª—ã
	for _, e := range files[copies:] {
		remoteFile := filepath.ToSlash(filepath.Join(dir, e.Name))
		log.Printf("üßπ (FTP) Deleting extra archive %s", remoteFile)
		_ = c.Delete(remoteFile)
	}
}
